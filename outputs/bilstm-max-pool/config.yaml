general:
  seed: 418
  device: auto
  threshold: 0.6

model:
  name: bilstm
  variant: max-pool
  bilstm:
    hidden_size: 256
    num_layers: 3
    dropout: 0.25

data:
  batch_size: 32
  preprocessing:
    max_length: 128
    tokenizer: bert-base-uncased

training:
  epochs: 15
  lr: 0.0005
  # optimizer: adam
  patience: 3

output_dir: outputs/
